{
  "papers": [
    {
      "id": "2010.08157v1",
      "chunks": [
        {
          "text": "3.2. The e\ufb00ectiveness of the AD model\n\nTo evaluate the performance of the AD model with di\ufb00erent parameters \u03c4 and \u03b1, we selected the testing time as the beginning of the year 2010 and the future time window Tf as 5 years. In this case, We used\n\n5\n\nthe data before 2010 to predict the popularity of papers, and used the data in a future time window of 5 years to test the performance. Figure 1 shows the result. From \ufb01gure 1, we could \ufb01nd that, for a given \u03b1, a suitable decay parameter \u03c4 can signi\ufb01cantly increase the prediction performance. This indicates that papers\u2019 temporal information plays an important role in predicting papers\u2019 popularity. The best performance of AD model can be achieved by a suitable value of \u03c4 and \u03b1. The highest precision is achieved when \u03b1 = 0.74 and t = 24, the highest Spearman rank correlation coe\ufb03cient is achieved when \u03b1 = 0.49 and t = 54, and the highest Pearson correlation coe\ufb03cient is achieved when \u03b1 = 0.54 and t = 18. As the three evaluation metrics focus on di\ufb00erent aspects, there is an appreciable discrepancy in the best parameters of the three evaluation metrics.\n\nA\n\nA\n\n120 0.64 0.63 0.62 100 0.61 0.60 0.59 80 0.58 0.57 60 0.56 0.55 0.54 40 0.53 0.52 0.51 20 0.50 0.49 B 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 120 0.72 0.71 100 0.70 80 0.69 60 0.68 40 0.67 20 0.66 C 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 120 0.87 0.86 0.85 100 0.84 0.83 0.82 80 0.81 0.80 60 0.79 0.78 0.77 40 0.76 0.75 0.74 20 0.73 0.72 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9\n\nFigure 1: The performance of the AD model with di\ufb00erent parameters \u03c4 and \u03b1. (A) Precision. (B) The Spearman rank correlation coe\ufb03cient. (C) The Pearson correlation coe\ufb03cient. The testing time is set as the beginning of the year 2010, and the future time window Tf is 5 years.\n\nWhile evaluating the performance of a prediction method, a small future time window Tf represents a\n\n6\n\nshort term popularity, and a large Tf represents a long term popularity. Therefore, we tested the performance of di\ufb00erent prediction methods under di\ufb00erent Tf to compare their performance. To eliminate the in\ufb02uence that may be caused by di\ufb00erent testing time, we obtained the \ufb01nal results by averaging the results of \ufb01ve randomly selected testing time t. To make sure that there is enough data in both the training set and the test set, the \ufb01ve randomly selected testing time t is select in the range from January 1990 to January 2006. The parameters for CiteRank and the AD model are selected as the one corresponding to the highest value of the target metric. Figure 2 shows the prediction performance of di\ufb00erent prediction method as a function of the future time window Tf.\n\n0.6 n o i s i c e 0.4 r P 0.2 1 2 3 4 5 6 7 8 9 10 0.8 0.6 PR CR AD RS 0.4 0.2 1 2 3 4 5 6 7 8 9 10 0.8 0.7 r 0.6 0.5 0.4 0.3 1 2 3 4 5 6 7 8 9 10",
          "section": "results",
          "distance": 0.38814638451633
        },
        {
          "text": "T\n\n(year)\n\nf\n\nFigure 2: The prediction performance PageRank (PR), CiteRank (CR), rescaled PageRank(RS) and age-based di\ufb00usion (AD) model under di\ufb00erent Tf. The results are obtained by averaging the results of 5 randomly select testing time t.\n\nFrom \ufb01gure 2, it is clear that the AD model outperforms other methods on all the three evaluation metrics for all Tf value. The performance of PageRank is signi\ufb01cantly worse than other methods. As PageRank model dose not take any temporal information while calculating the result, the prediction performance of PageRank may be limited. For CiteRank, rescaled PageRank, and the AD models, the precision and the\n\n7\n\nPearson correlation coe\ufb03cient have a small decrease with the increase of Tf. This indicates that it becomes more di\ufb03cult to predict a longer term popularity which may be in\ufb02uenced by more unexpected factors. But the Spearman rank correlation coe\ufb03cient increases with Tf. The reason may be that too many papers have the same real popularity value but di\ufb00erent prediction score when Tf is small, which can decrease the Spearman rank correlation coe\ufb03cient while comparing the di\ufb00erence between the two ranking list.\n\n10 10 10 10 10 10 3 3 3 R C 10 R P 10 S 10 R 2 2 2 10 10 10 1 1 1 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 AD AD AD 10\n\nFigure 3: The comparison of ranking results of the real top 1% papers. The x-axis is the ranking obtained by age-based di\ufb00usion (AD) model, and the y-axis is the ranking obtained by CiteRank (CR), PageRank (PR) and rescaled PageRank (RS) respectively. Black solid lines in all \ufb01gures are y = x, indicating that the dot on it has the same rankings in the two methods.\n\n3.3. Top Papers Analysis\n\nIn reality, people is more conscious of the papers that will be popular in the future rather than the real future popularity of all papers. So, we analyzed the ranking results of di\ufb00erent methods for the papers that are ranked as top 1% papers. We selected the testing time as the beginning of the year 2010 and the future time window Tf as 5 years in this subsection to analysis the results. The parameters for CiteRank and the AD model are selected as the one corresponding to the highest value of precision.\n\nFigure 3 shows the ranking results of CiteRank, PageRank and rescaled PageRank methods compared with the ranking result of the AD model for the papers that are ranked as top 1% papers by real future popularity. Black solid lines are y = x. If a dot is positioned up the solid lines, it means that the paper represented by the dot is ranked lower by the corresponding method than the AD model. It is clear that major parts of the dots are located up the y = x lines in all the three graphs. These indicate that, the AD model can rank the real top 1% papers higher than other three methods.\n\nFigure 4 shows the cumulative distribution of the age of the top 1% papers ranked by di\ufb00erent methods. The cumulative distribution of the real top 1% papers ranked by date in the future time window exponentially decays with age. This indicates that the number of papers ranked in the real top 1% decays rapidly with age, and only a small number of those papers are old papers. The cumulative distribution of the AD model has a similar exponential distribution as the real result. The distribution of CiteRank, PageRank, rescaled PageRank methods have an obvious deviation from the real result, and many old papers are ranked as top 1% papers.\n\nTo better understand the age bias of di\ufb00erent methods, we analyzed the ranking di\ufb00erence of di\ufb00erent methods for the real top 1% papers with di\ufb00erent age. We set the ranking di\ufb00erence of a paper as \u2206r = log(rp) \u2212 log(rf), where rf is the paper\u2019s real ranking in the future and rp is the paper\u2019s ranking by a prediction method. We take the logarithm of the rankings to avoid the in\ufb02uence of the lowly ranked papers while calculating the average result. \u2206r = 0 indicates the predicted ranking is echo to the real ranking, and the prediction method has a perfect performance; \u2206r > 0 indicates the prediction method underestimate the paper\u2019s popularity. \u2206r < 0 indicates the prediction method overrate the paper\u2019s popularity. Figure 5 shows the average value of \u2206r for the papers under di\ufb00erent age. This \ufb01gure only considers the real top 1% papers in the future time window. Figure 5 shows that, PageRank, CiteRank, and rescaled PageRank\n\n8\n\n1 0.1 n o i t u b i r t s i d 0.01 e v i t a RS l u m PR u c CR 1E-3 AD real 1E-4 0 20 40 60 80 100",
          "section": "other",
          "distance": 0.41623330537435876
        },
        {
          "text": "4. Conclusion and Discussion\n\nThe age-based di\ufb00usion (AD) model we propose in this paper is a model simulating the attention di\ufb00usion process along the citation networks. Researchers typically start \u201csur\ufb01ng\u201d scienti\ufb01c publications from a rather recent publication that catch their attention, and then they will follow the paper\u2019s references with the probability that is exponentially decaying with the paper\u2019s age and also decays with the iteration of steps. The AD model is a time-aware method, and we use it to predict the future popularity of scienti\ufb01c papers. We introduced three metrics to evaluate the performance in citation prediction: Pearson correlation coe\ufb03cient, Spearman rank correlation coe\ufb03cient and precision. The experimental results show that the AD model can improve the prediction accuracy compared with other benchmark methods. For some newly published papers that have not accumulated many citations but will be popular in the near future, the AD model can substantially improve their rankings. This is critical, because identifying the future highly\n\n10\n\ncited paper from thousands of new papers published each month would provide very valuable references for researchers.\n\nWhile predicting the future popularity of scienti\ufb01c papers using citation networks, we have to face the \u201dcold start\u201d problem. This problem refers to the case in which newly published papers have zero or few citations. Time-aware methods may increase the possibility to detect the potential popular papers that are newly published. But essentially, implementing time-aware methods still need citation information, and such kind of methods have inherent limitations to predict the popularity of newly published papers that have zero or few citations. Exploiting paper metadata is one way to solve the \u201ccold start\u201d problem. Although metadata based prediction methods do not seem to have signi\ufb01cant advantage in popularity prediction of papers[26], combining network based prediction methods with metadata based methods may eventually solve the \u201ccold start\u201d problem and have a much higher overall predict precision. This will be the direction of our future works on popularity prediction of scienti\ufb01c papers.",
          "section": "results",
          "distance": 0.41730703133901637
        }
      ],
      "themes": [
        "Popularity prediction",
        "Bibliometric analysis",
        "Temporal analysis",
        "Complex networks",
        "Research methods",
        "Diffusion",
        "cold start",
        "Autoregressive and Deterministic model"
      ],
      "methods": [
        "Matrix",
        "Network centrality",
        "Precision",
        "Scientific methodology",
        "Age-based decay",
        "stochastic process",
        "Correlation coefficient",
        "linear extrapolation",
        "Preferential attachment"
      ],
      "domains": [],
      "strengths": [],
      "limitations": [],
      "citations": [
        " 21",
        "26",
        "24",
        "20",
        " 14",
        "17",
        " 23",
        "9",
        "25",
        "6",
        "3",
        "14",
        "19",
        "4",
        "5",
        " 17",
        "10",
        "22",
        "18",
        "7",
        "21",
        "13",
        "16",
        "23",
        "2",
        "15",
        "1",
        "8",
        " 5",
        "12",
        "11"
      ],
      "graph_data": {
        "paper_id": "2010.08157v1",
        "title": "Predicting the popularity of scientific publications by an age-based diffusion model",
        "authors": [
          "Yanbo Zhou",
          "Qu Li",
          "Xuhua Yang",
          "Hongbing cheng"
        ],
        "chunk_ids": [
          "2010.08157v1_chunk_9",
          "2010.08157v1_chunk_8",
          "2010.08157v1_chunk_7",
          "2010.08157v1_chunk_6",
          "2010.08157v1_chunk_5",
          "2010.08157v1_chunk_4",
          "2010.08157v1_chunk_3",
          "2010.08157v1_chunk_2",
          "2010.08157v1_chunk_1",
          "2010.08157v1_chunk_0"
        ],
        "chunk_sections": [
          "other",
          "results"
        ],
        "chunk_citations": [],
        "themes": [
          "Research methods",
          "Temporal analysis",
          "Complex networks",
          "Diffusion",
          "Autoregressive and Deterministic model",
          "Bibliometric analysis",
          "Popularity prediction",
          "cold start"
        ],
        "methods": [
          "Preferential attachment",
          "Matrix",
          "Age-based decay",
          "linear extrapolation",
          "Precision",
          "stochastic process",
          "Scientific methodology",
          "Correlation coefficient",
          "Network centrality"
        ],
        "domains": [
          "Physical sciences",
          "Citation prediction"
        ],
        "theme_related_papers": [
          "2309.15973v2",
          "0708.2265v1"
        ],
        "method_related_papers": [
          "2309.15973v2"
        ],
        "domain_related_papers": [
          "0708.2265v1",
          "2309.15973v2"
        ]
      },
      "chunk_count": 10,
      "min_distance": 0.38814638451633
    },
    {
      "id": "2309.15973v2",
      "chunks": [
        {
          "text": "6. Conclusion, limitations and further research\n\n11\n\nTheoretical and especially empirical scientific researches of public policy require the application of adequate scientific research methodology. In addition to fulfilling the basic methodological requirements as a prerequisite for scientific research and social phenomena, it is also crucial to ensure the means and methods of obtaining relevant data. In this sense, it is necessary to use adequate methods of obtaining data on public policy, in order to be able to draw relevant conclusions, and to enact better and more efficient public policy. Processed methods, as well as data acquisition techniques, are applicable in public policy research, with the fact that some of them are applied on a larger scale, and some on a smaller scale.\n\nThe analyzed methods and two techniques (interview and survey) are suitable for obtaining data on the manifestation of the social phenomenon of public policy. From these identifications, the results of individual public policy, depends on what will be done in the future, i.e. whether it will be necessary to enact new or the same public policy in solving specific socio-political problems. These data, in later stages and processes, can be used as true indicators of the success or failure of adopted public policy. Therefore, it is also necessary that the makers of public decisions (public policy) themselves know the presented methods and techniques of obtaining data on public policy, so that in the end efficient and fair public decisions (public policy) are made.\n\nReferences\n\nColebatch, H., 2004. Policy. Fakultet politi\u010dkih znanosti Sveu\u010dili\u0161ta u Zagrebu. Esmark, A. and Triantafillou, P., 2007. Document Analysis of Network Topography and Network Programmes, in: Bogason, P. and Z\u00f8lner, M., (ed.). Methods in Democratic Network Governance. Palgrave Macmillian.\n\nGrde\u0161i\u0107, I., 2006. Osnove analize javnih politika. Fakultet politi\u010dkih znanosti Sveu\u010dili\u0161ta u Zagrebu.\n\nHalmi, A., 2005. Strategije kvalitativnih istra\u017eivanja u primijenjenim dru\u0161tvenim znanostima. Naklada Slap.\n\nHeywood, A., 2004. Politika. Clio.\n\nHowlett, M. and Ramesh M., 1995. Studying Public Policy: Policy Cycles and Policy Subsystems. Oxford University Press.\n\nMio\u0161i\u0107, N. et al., 2014. Analiza i zagovaranje javnih politika. EDU centar GONG-a/Centar za cjelo\u017eivotno obrazovanje Fakulteta politi\u010dkih znanosti Sveu\u010dili\u0161ta u Zagrebu.\n\n12\n\nPetak, Z., 2002. Komparativne javne politike: mogu li se uspore\u0111ivati rezultati djelovanja vlada?. Politi\u010dka misao. 39 (1), 51-62.\n\nPetek, A., 2011. Transformacija politike prema osobama s invaliditetom u Hrvatskoj: analiza ciljeva. Anali Hrvatskog politolo\u0161kog dru\u0161tva. 7, 101-122.\n\nPetek, A., 2012. Transformacija politike prema osobama s invaliditetom: primjena policy mre\u017ea - doktorska disertacija. Fakultet politi\u010dkih znanosti.\n\nPriru\u010dnik za analizu javnih politika: Uvod u proces kreiranja javnih politika na lokalnom nivou. 2007. ALDI \u2013 Agencija za lokalne razvojne inicijative.\n\n\u0160e\u0161i\u0107, B., 1983. Osnovi logike. Nau\u010dna knjiga, Beograd 1983.\n\nTahirovi\u0107, E. and Kuka, E., 2020. Osnove javnih politika. Univerzitet u Sarajevu, Fakultet za upravu \u2013 pridru\u017eena \u010dlanica.\n\nTermiz, D\u017e., 2006. Statisti\u010dke tehnike i postupci u politikolo\u0161kim istra\u017eivanjima. NIK \u201cGrafit\u201c. Termiz, D\u017e., 2013. Osnovi metodologije socijalne psihologije. Amos Graf.\n\nTermiz, D\u017e., 2022. Metodologija dru\u0161tvenih nauka \u2013 tre\u0107e izmijenjeno i dopunjeno izdanje. Fakultet politi\u010dkih nauka Univerziteta u Sarajevu/Me\u0111unarodno udru\u017eenje metodologa dru\u0161tvenih nauka.\n\nVujevi\u0107, M., 1990. Uvo\u0111enje u znanstveni rad u podru\u010dju dru\u0161tvenih znanosti. Informator.\n\n13",
          "section": "other",
          "distance": 0.4820444211847992
        },
        {
          "text": "This method implies a systematic, quantitative and qualitative analysis of the obtained data through the analysis of the most diverse forms of human creations (written, pictorial, artistic and similar). The success of document analysis (content) is based on \u201equality-selected analysis categories. Categories of analysis are what is sought to be found and coded in the content\u201c (Grde\u0161i\u0107, 2006, p. 41). Therefore, when using the method of document analysis (content) in scientific research, including public policy research, both quantitative and qualitative analysis (content) of documents are used. This method is particularly used when analyzing normative and regulatory state acts (constitutions, laws, regulations, regulations, strategies, etc.).\n\nExamination is a frequently applied method of obtaining data when researching public policy. The survey is \u201ea very complex and favorite method of direct and at the same time indirect collection of data about the social reality and from it itself... The survey is carried out\n\n5\n\nby asking a question, clear and meaningful, to the respondent who voluntarily and consciously\n\nanswers\u201c (Termiz, 2022, p. 383). This method directly obtains the relevant and requested data from the respondents. Therefore, according to many scientists and public policy researchers, this method has taken the place of an indispensable method in policy analysis. This is more due to the fact that it implies, first of all, the use of the interview technique, \u201einterviewing members of the policy community, policy actors and entrepreneurs, experts, politicians or members of the political and decision-making elite\u201c (Grde\u0161i\u0107, 2006, p. 64). It can serve as an important substitute and supplement for already obtained data through the analysis (content) of documents. Just as the selection of relevant documents is important in the analysis (content) of documents, so in the method of examination (interview) the determination of the sample for examination (interview) is very important. The sample (respondents) is, when researching public policy, most often intentionally determined, depending on what and what kind of data is to be obtained. In this sense, special attention should be paid to the wording and selection of questions. This is more due to the fact that when using this method in policy-research, the most and most often interviewing of elites (experts for certain fields and topics) is carried out. As Ivan Grde\u0161i\u0107 emphasizes, the examination can \u201eilluminate the world of political networks and communities. Policy-relevant research is focused on the real world of political actors, ways of social and political construction of problems, interpretation of interest structures, human experiences, behavior and values\u201c (Grde\u0161i\u0107, 2006, p. 69). Survey as a technique of obtaining data has its wide application in social sciences, including political sciences. Survey research provides shorter data, primarily numerical data, which are later statistically analyzed and processed. In this method too, the determination of a relevant and representative sample is extremely important. The majority of scientists and researchers are of the opinion that a sample in the range of 300-400 respondents is a sufficiently representative sample for further conclusions. In the analysis of public policy, polls are \u201esuitable for determining the real needs or experiences of citizens in a policy, related to setting the policy on the agenda, but also for obtaining new information about the behavior of users of a service. Then, polls are good for analyzing public opinion, and in the analysis of public policy, especially in relation to support\n\nfor certain solutions in the formulation phase. Also, as a method, the survey is suitable for\n\ncollecting data on issues of the impact of a certain policy and evaluation of the effectiveness of\n\nan existing program in their evaluation.\u201c (Mio\u0161i\u0107 et al., 2014, p. 41). Therefore, the survey is\n\nsuitable for obtaining data in all phases of the policy process, which ranks it among the most\n\napplied methods of policy analysis. The selection, formulation, and order of questions, as well\n\nas the size and complexity of the survey itself (number of questions and comprehensibility) are\n\n6\n\nextremely important in the survey. In this context, the basic features of a good questionnaire are: (Mio\u0161i\u0107 et al., 2014, p. 41):\n\n- comprehensibility and clarity of the question;\n\n- principle: one question \u2013 one possible answer;\n\n- brevity of the question;\n\n- clear time frame (next year or past year, NOT \u201cin the future\u201c or \u201cin the past\u201c);\n\n- value-free questions;\n\n- non-suggestive questions;\n\n- question filter: in order to determine the actual level of knowledge of the respondents.\n\nThe data obtained through the survey \u201efor the needs of the administrative bodies of the state are most often used to explain or continue the started programs. More for the justification of the policy, than for its initial design. Surveys in a policy-making environment can be useful for policy promotion, measuring its success, but they are of little use when specialist knowledge about hard-to-reach and complex policy-problems is needed\u201c (Grde\u0161i\u0107, 2006, p. 54-55).\n\nObservation is a method that is also applied in public policy research. Observation is \u201ea method of collecting data through direct sensory observation - observation... It is about conscious observation \u2013 observation\u201c (Termiz, 2022, p. 378). Policy-analysts and researchers, using this method, in a direct (observation of current phenomena) or indirect (observation of past phenomena based on preserved human creations) way, gain personal insight into the relevant facts and the state of reality, and based on that, obtain the necessary data. Namely, \u201eold solutions to problems can serve as inspiration for developing new ones, more suitable for modern conditions\u201c (Grde\u0161i\u0107, 2006, p. 34).\n\nExperiment is a method of obtaining data that is used to a lesser extent in public policy research than is the case with other methods. An experiment is \u201ea method in which an experimental situation is created artificially, with an experimental factor, which is purposefully managed and based on the results of which key knowledge is formed\u201c (Termiz, 2022, p. 399). An experiment is \u201eany research in which a certain phenomenon is studied under controlled conditions, regardless of how it was created, naturally or artificially\u201c (Vujevi\u0107, 1990, p. 83). Thus, the policy-model, as a result of the process of structuring policy problems, enables the policy-analyst to experiment with different types of issues. In this way, relevant data is obtained, which helps the subsequent simpler and easier communication and connection between the policy-analyst and the client of the policy-analysis, and ultimately the audience itself.",
          "section": "methodology",
          "distance": 0.49561357153076957
        },
        {
          "text": "2012, p. 202).\n\nGraphical analysis and presentation of data is an extremely significant and important method of data analysis in policy research. Everything that can be expressed in numerical quantities can also be shown in graphic form. In graphic representation, \u201ethe basis consists of 10\n\nalready formed numerical statements according to which graphic statements are specially constructed using geometric images, figures, points, lines, surfaces and various bodies\u201c (Termiz, 2006, p. 153-166).\n\nPolicy researchers are required to, by using graphs, interest policy research clients, and the wider public, in the results that have been reached, especially since they often deal with extremely complex problems and questions. Because, \u201ea successful graph tells us that the analyst has succeeded in bringing the researched variables (groups of data) into a meaningful relationship and that he understands their mutual interaction\u201c (Grde\u0161i\u0107, 2006, p. 83). For this purpose, different types of charts are used, such as: pie chart - pie or cake, histogram - columns as values, merged columns and layered charts, scatter chart, line chart - trend picture. It is important to emphasize that every graphic representation should be accompanied by a proper and accurate textual description. In addition, it should have a title, legend, variable names, visibly displayed values and data, and the like.\n\nComparative data analysis is important due to the fact that it enables the identification of previous good practices in other areas, other policy or other countries. Such insights can be very useful in using the obtained data in solving current issues and problems, which puts policy analysts in a situation where they are already one step ahead of the established starting (initial) place.\n\nCost-benefit analysis concerns, above all, financial indicators and relationships. It is applied in public policy research in situations where it is necessary to decide whether to invest financial means and resources in certain public policy or not, in order to solve socio-political (public policy) problems. It tries to show all variables in the form of monetary value. It is also one of the key limitations of this method, given the fact that not all variables can be presented in such a (monetary) form.\n\nActor analysis is one of the most well-known methods of analysis within public policy. This method determines the number, character, scope, structure, properties, competencies, interrelationships, as well as other variables related to the actors of the process of creating and implementing public policy. In this context, this analysis is particularly important during the process of public policy advocacy, in which relevant and accurate knowledge of the actors involved is crucial in initiating procedures and procedures for the advocacy and representation of various public policy.",
          "section": "methodology",
          "distance": 0.5090682779932063
        }
      ],
      "themes": [
        "Research methods",
        "Temporal analysis",
        "Public policy analysis"
      ],
      "methods": [
        "inductive coding",
        "Data processing techniques",
        "Scientific methodology",
        "Policy community interviews",
        "Assessment",
        "Analysis"
      ],
      "domains": [],
      "strengths": [],
      "limitations": [],
      "citations": [],
      "graph_data": {
        "paper_id": "2309.15973v2",
        "title": "Application of data acquisition methods in the field of scientific research of public policy",
        "authors": [
          "Kuka Ermin",
          "Tahirovic Emir"
        ],
        "chunk_ids": [
          "2309.15973v2_chunk_6",
          "2309.15973v2_chunk_5",
          "2309.15973v2_chunk_4",
          "2309.15973v2_chunk_3",
          "2309.15973v2_chunk_2",
          "2309.15973v2_chunk_1",
          "2309.15973v2_chunk_0"
        ],
        "chunk_sections": [
          "other",
          "methodology"
        ],
        "chunk_citations": [],
        "themes": [
          "Research methods",
          "Temporal analysis",
          "Public policy analysis"
        ],
        "methods": [
          "Policy community interviews",
          "Assessment",
          "inductive coding",
          "Data processing techniques",
          "Analysis",
          "Scientific methodology"
        ],
        "domains": [
          "Policy studies",
          "Probabilistic processes",
          "Citation prediction"
        ],
        "theme_related_papers": [
          "2010.08157v1"
        ],
        "method_related_papers": [
          "2010.08157v1"
        ],
        "domain_related_papers": [
          "0708.2265v1",
          "2010.08157v1"
        ]
      },
      "chunk_count": 5,
      "min_distance": 0.4820444211847992
    }
  ],
  "images": [
    {
      "path": "output\\images\\0eb26194-bdb1-4103-bb1b-f4de7eab83da.jpg",
      "paper_id": "2010.08157v1",
      "description": "The figure illustrates the architecture of a deep reinforcement learning model designed for playing Atari games, specifically focusing on the integration of a convolutional neural network (CNN) for feature extraction and a long short-term memory (LSTM) network for temporal sequence processing. The architecture diagram shows the flow of information from the input layer, consisting of raw pixel data from game frames, through several convolutional layers that capture spatial hierarchies. These are ...",
      "themes": [
        "cold start",
        "Popularity prediction",
        "Bibliometric analysis",
        "Autoregressive and Deterministic model",
        "Diffusion",
        "Complex networks",
        "Temporal analysis",
        "Research methods"
      ],
      "methods": [
        "Network centrality",
        "Correlation coefficient",
        "Scientific methodology",
        "stochastic process",
        "Precision",
        "linear extrapolation",
        "Age-based decay",
        "Matrix",
        "Preferential attachment"
      ],
      "domains": [],
      "distance": 0.46516781050828904
    },
    {
      "path": "output\\images\\5988287f-778c-4696-9157-58e6bf892339.jpg",
      "paper_id": "2010.08157v1",
      "description": "This figure illustrates the architecture of a convolutional neural network (CNN) designed for image analysis, specifically targeting breast cancer classification. The diagram includes several layers of the network, starting with input images of size 50x50 pixels. The architecture comprises multiple convolutional layers (Conv2D) with varying filter sizes, followed by max-pooling layers to downsample the feature maps. Each layer is labeled with its respective output size and number of filters, pro...",
      "themes": [
        "cold start",
        "Popularity prediction",
        "Bibliometric analysis",
        "Autoregressive and Deterministic model",
        "Diffusion",
        "Complex networks",
        "Temporal analysis",
        "Research methods"
      ],
      "methods": [
        "Network centrality",
        "Correlation coefficient",
        "Scientific methodology",
        "stochastic process",
        "Precision",
        "linear extrapolation",
        "Age-based decay",
        "Matrix",
        "Preferential attachment"
      ],
      "domains": [],
      "distance": 0.4742807790412773
    },
    {
      "path": "output\\images\\4fdfb20f-533c-40a6-bd1b-569e87dd1367.jpg",
      "paper_id": "0708.2265v1",
      "description": "I'm unable to directly analyze images or diagrams from research papers. However, if you can describe the components, graphs, or details in the figure, I can help interpret them. Let me know how you'd like to proceed!",
      "themes": [
        "polynomial expansion",
        "dispersive wave motion",
        "complex variables",
        "Fractional calculus",
        "Mittag-Leffler function",
        "Diffusion",
        "Green's functions",
        "convergence of series",
        "Rising factorial",
        "Integral Transforms"
      ],
      "methods": [
        "Fractional calculus",
        "parameterization",
        "Power series expansion",
        "Caputo fractional derivative",
        "Theorem development",
        "Mittag-Leffler function analysis",
        "Integral Transforms"
      ],
      "domains": [],
      "distance": 0.4762409446414907
    },
    {
      "path": "output\\images\\19d3d1d1-2979-47ac-9fe6-ce11ebfb8917.jpg",
      "paper_id": "2010.08157v1",
      "description": "The figure consists of three scatter plots that compare different datasets or variables against a common variable labeled \"AD.\" Each plot uses a logarithmic scale on both axes, illustrating the relationships between:\n\n1. **Left Plot:** Compares \"CR\" on the y-axis with \"AD\" on the x-axis. The data points are densely clustered, showing a positive correlation, as indicated by their alignment along the diagonal line.\n\n2. **Middle Plot:** Compares \"PR\" on the y-axis with \"AD\" on the x-axis. The scatt...",
      "themes": [
        "cold start",
        "Popularity prediction",
        "Bibliometric analysis",
        "Autoregressive and Deterministic model",
        "Diffusion",
        "Complex networks",
        "Temporal analysis",
        "Research methods"
      ],
      "methods": [
        "Network centrality",
        "Correlation coefficient",
        "Scientific methodology",
        "stochastic process",
        "Precision",
        "linear extrapolation",
        "Age-based decay",
        "Matrix",
        "Preferential attachment"
      ],
      "domains": [],
      "distance": 0.4916173395742047
    },
    {
      "path": "output\\images\\538e3c4a-b3aa-4339-ae8c-5ec607314913.jpg",
      "paper_id": "2010.08157v1",
      "description": "This figure presents a line graph depicting the relationship between age (years) and a variable denoted as \u0394r. Four different datasets or groups are represented: PR (green triangles), RS (blue circles), AD (yellow squares), and CR (red hexagons), as indicated by the legend. The x-axis represents age, ranging from 0 to 90 years, while the y-axis shows the \u0394r values, which range from -3 to 4. Each line represents how \u0394r changes with age for each group. The graph likely illustrates key trends or di...",
      "themes": [
        "cold start",
        "Popularity prediction",
        "Bibliometric analysis",
        "Autoregressive and Deterministic model",
        "Diffusion",
        "Complex networks",
        "Temporal analysis",
        "Research methods"
      ],
      "methods": [
        "Network centrality",
        "Correlation coefficient",
        "Scientific methodology",
        "stochastic process",
        "Precision",
        "linear extrapolation",
        "Age-based decay",
        "Matrix",
        "Preferential attachment"
      ],
      "domains": [],
      "distance": 0.4942402650601342
    }
  ]
}